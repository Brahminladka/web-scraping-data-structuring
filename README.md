# ğŸ—‚ï¸ Web Scraping & Data Structuring Projects â€“ Yasham Software Services Pvt. Ltd.

## ğŸ“Œ Overview
This repository contains **two major Python-based web scraping solutions** developed during my internship at **Yasham Software Services Pvt. Ltd.**:
1. **Earth911 Recycling Locator Scraper** â€“ Extracts information about recycling centers from Earth911.com.
2. **BestBuy Store Locator Scraper** â€“ Collects detailed store data including services and phone numbers from BestBuy.com.

Both scripts use **Selenium** for browser automation, **BeautifulSoup** for parsing HTML, and **Pandas** for structuring scraped data into CSV format.

---

## ğŸš€ Features
- âœ… Dynamic scraping of JavaScript-rendered content  
- âœ… Pagination handling for multiple pages  
- âœ… Cleans and structures data for analytics  
- âœ… Saves results in **CSV** format  
- âœ… Error handling and logging for better reliability  

---

## ğŸ› ï¸ Technologies Used
- Python 3
- Selenium (Edge WebDriver)
- BeautifulSoup4
- Pandas
- Regular Expressions (re)

---

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ earth911_final.py                # Earth911 scraping script
â”œâ”€â”€ bestbuy.py                       # BestBuy scraping script
â”œâ”€â”€ msedgedriver.exe                 # Microsoft Edge WebDriver
â”œâ”€â”€ recycling_locations.csv          # Sample output for Earth911
â”œâ”€â”€ bestbuy_stores_with_details.csv  # Sample output for BestBuy
â””â”€â”€ README.md                        # Project documentation
```

---

# ğŸŒ **1. Earth911 Recycling Locator Scraper**

### âœ… Description
Automates the extraction of recycling center details from **Earth911.com**, including business names, addresses, accepted materials, and last update dates.

### â–¶ï¸ Usage Instructions
1. Install required dependencies:
   ```bash
   pip install selenium beautifulsoup4 pandas
   ```
2. Ensure `msedgedriver.exe` is in the same directory.
3. Run the script:
   ```bash
   python earth911_final.py
   ```
4. Output is saved as **`recycling_locations.csv`**.

### ğŸ”§ Configuration
Modify parameters in `main()` to customize scraping:
```python
results = scraper.scrape(
    material_type='Electronics',
    location='10001',
    max_distance=100,
    max_pages=5
)
```

---

# ğŸ¬ **2. BestBuy Store Locator Scraper**

### âœ… Description
Scrapes store details from **BestBuy.com**, including name, address, phone, services, store hours, and more.

### âš ï¸ Important Note
After Microsoft Edge opens, **you may need to manually refresh the website once** if it does not load properly during scraping.  
This ensures the elements are loaded correctly for Selenium to proceed.

### â–¶ï¸ Usage Instructions
1. Install required dependencies:
   ```bash
   pip install selenium pandas
   ```
2. Keep `msedgedriver.exe` in the same folder as the script.
3. Run the scraper:
   ```bash
   python bestbuy.py
   ```
4. Scraped data will be saved as **`bestbuy_stores_with_details.csv`**.

---

## âœ… Example Output

### Earth911 Sample:
| Business Name   | Last Updated | Address                | Materials Category | Accepted Materials |
|-----------------|--------------|------------------------|--------------------|--------------------|
| XYZ Recycling   | 2025-07-26   | 123 Main St, New York  | Electronics        | TVs, Batteries     |

### BestBuy Sample:
| Store Name      | Phone        | Services                |
|-----------------|--------------|-------------------------|
| Best Buy NYC    | (212) 555-1234 | Geek Squad, Curbside Pickup |

---

## ğŸ¢ Project Context
These projects were implemented during my internship at **Yasham Software Services Pvt. Ltd.** under the **Python Web Scraping & Data Structuring** module.  
They demonstrate:
- Automated extraction of structured data from dynamic websites
- Use of Selenium for web automation
- Handling pagination, delays, and data cleaning
- Exporting structured CSV outputs for analytics

---

## âœ… Author
**Aman Tiwari**  
Intern - Python Web Scraping & Data Structuring  
Yasham Software Services Pvt. Ltd.
